{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf30fc9-aebc-44a0-95de-50367615dcef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# general imports\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me2e_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m E2EModel\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Fading\\e2e_model.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# e2e_model.py\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msionna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Mapper, Demapper\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msionna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mphy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AWGN\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# general imports\n",
    "from e2e_model import E2EModel\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CORRECTED Sionna imports ---\n",
    "\n",
    "# PlotBER is in sionna.utils\n",
    "from sionna.phy.utils.plotting import PlotBER\n",
    "from sionna.phy.fec.linear import LinearEncoder\n",
    "\n",
    "\n",
    "# LDPC Encoders and Decoders\n",
    "from sionna.phy.fec.ldpc import LDPCBPDecoder, LDPC5GEncoder, LDPC5GDecoder\n",
    "# General FEC utility\n",
    "from sionna.phy.fec.utils import gm2pcm, load_parity_check_examples\n",
    "\n",
    "# --- End of corrected imports ---\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from gnn import * # load GNN functions\n",
    "from wbp import * # load weighted BP functions\n",
    "\n",
    "print(f\"All modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c58ffc-55c9-46d7-87ad-ccc85beb58ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 0\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 1 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6df32b7e-7969-4a63-8481-6f5835468fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.framework.config.list_physical_devices(device_type=None)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8202e5-2920-4bd6-bc77-342a5932a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----- LDPC 5G -----\n",
    "params={\n",
    "    # --- Code Parameters ---\n",
    "        \"code\": \"5G-LDPC\",\n",
    "        \"n\": 140,\n",
    "        \"k\": 60,\n",
    "    # --- GNN Architecture ----\n",
    "        \"num_embed_dims\": 16,\n",
    "        \"num_msg_dims\": 16,\n",
    "        \"num_hidden_units\": 48,\n",
    "        \"num_mlp_layers\": 3,\n",
    "        \"num_iter\": 10,\n",
    "        \"reduce_op\": \"sum\",\n",
    "        \"activation\": \"relu\",\n",
    "        \"clip_llr_to\": 20,\n",
    "        \"use_attributes\": False,\n",
    "        \"node_attribute_dims\": 0,\n",
    "        \"msg_attribute_dims\": 0,\n",
    "        \"return_infobits\": False,\n",
    "        \"use_bias\": True,\n",
    "    # --- Training ---- #\n",
    "        \"batch_size\": [128, 128, 128], # bs, iter, lr must have same dim\n",
    "        \"train_iter\": [35000, 300000, 300000],\n",
    "        \"learning_rate\": [5e-4, 1e-4, 1e-5],\n",
    "        \"ebno_db_train\": [2, 8.],\n",
    "        \"ebno_db_eval\": 2.,\n",
    "        \"batch_size_eval\": 1000, # batch size only used for evaluation during training\n",
    "        \"eval_train_steps\": 1000, # evaluate model every N iters\n",
    "    # --- Log ----\n",
    "        \"save_weights_iter\": 10000, # save weights every X iters\n",
    "        \"run_name\": \"LDPC_5G_01\", # name of the stored weights/logs\n",
    "        \"save_dir\": \"results/\", # folder to store results\n",
    "    # --- MC Simulation parameters ----\n",
    "        \"eval_num_iter\": 10, # number of decoding iters to evaluate\n",
    "        \"mc_iters\": 100,\n",
    "        \"mc_batch_size\": 1000,\n",
    "        \"num_target_block_errors\": 500,\n",
    "        \"ebno_db_min\": 0.,\n",
    "        \"ebno_db_max\": 4.5,\n",
    "        \"ebno_db_stepsize\": 0.5,\n",
    "        \"eval_ns\": [140, 280, 420, 280, 280, 280], # evaluate different lengths\n",
    "        \"eval_ks\": [60, 120, 180, 120, 90, 150],\n",
    "        \"sim_esno\": False, # simulate results in EsN0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c7e6bf-4337-4518-a04b-692d68f76ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 5G NR LDPC code\n"
     ]
    },
    {
     "ename": "AlreadyExistsError",
     "evalue": "{{function_node __wrapped__Pack_N_1_device_/job:localhost/replica:0/task:0/device:GPU:0}} TensorFlow device (GPU:0) is being mapped to multiple devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not currently supported, see https://github.com/tensorflow/tensorflow/issues/19083 [Op:Pack] name: stack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m n \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      8\u001b[0m encoder_5g \u001b[38;5;241m=\u001b[39m LDPC5GEncoder(k, n)\n\u001b[1;32m----> 9\u001b[0m decoder_5g \u001b[38;5;241m=\u001b[39m \u001b[43mLDPC5GDecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_5g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_num_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mreturn_infobits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mprune_pcm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m pcm,_ \u001b[38;5;241m=\u001b[39m generate_pruned_pcm_5g(decoder_5g, n)\n\u001b[0;32m     16\u001b[0m n_no_rm \u001b[38;5;241m=\u001b[39m pcm\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\sionna\\phy\\fec\\ldpc\\decoding.py:1392\u001b[0m, in \u001b[0;36mLDPC5GDecoder.__init__\u001b[1;34m(self, encoder, cn_update, vn_update, cn_schedule, hard_out, return_infobits, num_iter, llr_max, v2c_callbacks, c2v_callbacks, prune_pcm, return_state, precision, **kwargs)\u001b[0m\n\u001b[0;32m   1389\u001b[0m         cn_schedule\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marange(z) \u001b[38;5;241m+\u001b[39m i\u001b[38;5;241m*\u001b[39mz)\n\u001b[0;32m   1390\u001b[0m     cn_schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(cn_schedule, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m-> 1392\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(pcm,\n\u001b[0;32m   1393\u001b[0m                  cn_update\u001b[38;5;241m=\u001b[39mcn_update,\n\u001b[0;32m   1394\u001b[0m                  vn_update\u001b[38;5;241m=\u001b[39mvn_update,\n\u001b[0;32m   1395\u001b[0m                  cn_schedule\u001b[38;5;241m=\u001b[39mcn_schedule,\n\u001b[0;32m   1396\u001b[0m                  hard_out\u001b[38;5;241m=\u001b[39mhard_out,\n\u001b[0;32m   1397\u001b[0m                  num_iter\u001b[38;5;241m=\u001b[39mnum_iter,\n\u001b[0;32m   1398\u001b[0m                  llr_max\u001b[38;5;241m=\u001b[39mllr_max,\n\u001b[0;32m   1399\u001b[0m                  v2c_callbacks\u001b[38;5;241m=\u001b[39mv2c_callbacks,\n\u001b[0;32m   1400\u001b[0m                  c2v_callbacks\u001b[38;5;241m=\u001b[39mc2v_callbacks,\n\u001b[0;32m   1401\u001b[0m                  return_state\u001b[38;5;241m=\u001b[39mreturn_state,\n\u001b[0;32m   1402\u001b[0m                  precision\u001b[38;5;241m=\u001b[39mprecision,\n\u001b[0;32m   1403\u001b[0m                  \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\sionna\\phy\\fec\\ldpc\\decoding.py:255\u001b[0m, in \u001b[0;36mLDPCBPDecoder.__init__\u001b[1;34m(self, pcm, cn_update, vn_update, cn_schedule, hard_out, num_iter, llr_max, v2c_callbacks, c2v_callbacks, return_state, precision, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cn_schedule, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m cn_schedule\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflooding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduling \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflooding\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cn_schedule \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_cns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(cn_schedule) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cn_schedule, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    257\u001b[0m     cn_schedule \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(cn_schedule, tf\u001b[38;5;241m.\u001b[39mint32)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\sionna_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: {{function_node __wrapped__Pack_N_1_device_/job:localhost/replica:0/task:0/device:GPU:0}} TensorFlow device (GPU:0) is being mapped to multiple devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not currently supported, see https://github.com/tensorflow/tensorflow/issues/19083 [Op:Pack] name: stack"
     ]
    }
   ],
   "source": [
    "# all codes must provide an encoder-layer and a pcm\n",
    "if params[\"code\"]==\"5G-LDPC\":\n",
    "    print(\"Loading 5G NR LDPC code\")\n",
    "\n",
    "    k = params[\"k\"]\n",
    "    n = params[\"n\"]\n",
    "\n",
    "    encoder_5g = LDPC5GEncoder(k, n)\n",
    "    decoder_5g = LDPC5GDecoder(encoder_5g,\n",
    "                               num_iter=params[\"eval_num_iter\"],\n",
    "                               return_infobits=False,\n",
    "                               prune_pcm=True)\n",
    "\n",
    "    pcm,_ = generate_pruned_pcm_5g(decoder_5g, n)\n",
    "\n",
    "    n_no_rm = pcm.shape[1]\n",
    "    k_no_rm = pcm.shape[1] - pcm.shape[0]\n",
    "\n",
    "    # create encoder without rate-matching\n",
    "    u_ref = np.eye(k)\n",
    "    c_ref = encoder_5g(u_ref).numpy()\n",
    "    gm = np.concatenate([u_ref[:,:2*encoder_5g._z], c_ref], axis=1)\n",
    "    encoder_no_rm = LinearEncoder(gm, is_pcm=False)\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Unknown code type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5616a903-51b7-4fc3-83c8-170f0a542fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ber_plot = PlotBER(f\"GNN-based Decoding - {params['code']}, (k,n)=({k},{n})\")\n",
    "ebno_dbs = np.arange(params[\"ebno_db_min\"],\n",
    "                     params[\"ebno_db_max\"]+1,\n",
    "                     params[\"ebno_db_stepsize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326abc4-0e2e-4713-8a6a-05985c016cf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --- Uncoded QPSK BER Simulation (Sionna 1.2.1) ---\n",
    "\n",
    "import tensorflow as tf\n",
    "from e2e_model import E2EModel\n",
    "\n",
    "# Use earlier k,n if defined; otherwise default\n",
    "k = k if 'k' in globals() else 100\n",
    "n = n if 'n' in globals() else 100\n",
    "\n",
    "# Create uncoded model\n",
    "e2e_uncoded = E2EModel(None, None, k=k, n=n, modulation=\"qam\", num_bits_per_symbol=2)\n",
    "\n",
    "# --- Soft-output (LLR) Monte Carlo function ---\n",
    "def mc_fun_soft(batch_size, ebno_db):\n",
    "    \"\"\"For soft_estimates=True: returns (bits, LLRs)\"\"\"\n",
    "    b = tf.random.uniform([batch_size, k], maxval=2, dtype=tf.int32)\n",
    "    llr = e2e_uncoded(b, ebno_db=ebno_db, return_llr=True)\n",
    "    return b, llr\n",
    "\n",
    "# --- Hard-decision Monte Carlo function ---\n",
    "def mc_fun_hard(batch_size, ebno_db):\n",
    "    \"\"\"For soft_estimates=False: returns (bits, hard decisions)\"\"\"\n",
    "    b = tf.random.uniform([batch_size, k], maxval=2, dtype=tf.int32)\n",
    "    b_hat = e2e_uncoded(b, ebno_db=ebno_db, return_llr=False)\n",
    "    return b, b_hat\n",
    "\n",
    "# --- Simulate both curves ---\n",
    "ber_plot.simulate(\n",
    "    mc_fun_soft,\n",
    "    ebno_dbs=ebno_dbs,\n",
    "    batch_size=params[\"mc_batch_size\"],\n",
    "    num_target_block_errors=params[\"num_target_block_errors\"],\n",
    "    legend=\"Uncoded (Soft LLR)\",\n",
    "    soft_estimates=True,\n",
    "    max_mc_iter=params[\"mc_iters\"],\n",
    "    forward_keyboard_interrupt=False,\n",
    "    show_fig=False,\n",
    ")\n",
    "\n",
    "ber_plot.simulate(\n",
    "    mc_fun_hard,\n",
    "    ebno_dbs=ebno_dbs,\n",
    "    batch_size=params[\"mc_batch_size\"],\n",
    "    num_target_block_errors=params[\"num_target_block_errors\"],\n",
    "    legend=\"Uncoded (Hard Decision)\",\n",
    "    soft_estimates=False,\n",
    "    max_mc_iter=params[\"mc_iters\"],\n",
    "    forward_keyboard_interrupt=False,\n",
    "    show_fig=False,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2ac4df-9883-48b2-81a2-2da5eb0eb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect one entry of ber_plot._bers to see what it contains\n",
    "for i, entry in enumerate(ber_plot._bers):\n",
    "    print(f\"\\nEntry {i}: type = {type(entry)}\")\n",
    "    if isinstance(entry, (list, tuple)):\n",
    "        print(f\"  Length = {len(entry)}\")\n",
    "        for j, item in enumerate(entry):\n",
    "            print(f\"   [{j}] type = {type(item)}, shape = {getattr(item, 'shape', None)}\")\n",
    "    else:\n",
    "        print(entry)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e229b9c4-128b-4cfe-980a-ea7e71f4a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's inspect what's inside ber_plot._bers to see the real structure\n",
    "for i, entry in enumerate(ber_plot._bers):\n",
    "    print(f\"\\nEntry {i}: type = {type(entry)}\")\n",
    "    if isinstance(entry, dict):\n",
    "        print(\"  Keys:\", list(entry.keys()))\n",
    "        for k, v in entry.items():\n",
    "            print(f\"   {k}: type={type(v)}, shape={getattr(v, 'shape', None)}\")\n",
    "    elif isinstance(entry, (list, tuple)):\n",
    "        print(f\"  Length = {len(entry)}\")\n",
    "        for j, item in enumerate(entry):\n",
    "            print(f\"   [{j}] type = {type(item)}, shape = {getattr(item, 'shape', None)}\")\n",
    "    else:\n",
    "        print(\"  Value:\", entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb821106-baf7-41ef-8424-306ddff3cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "ebno_db = tf.convert_to_tensor(ebno_dbs).numpy()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "# one tensor per legend (same length)\n",
    "for ber_tensor, legend in zip(ber_plot._bers, ber_plot._legends):\n",
    "    ber = tf.convert_to_tensor(ber_tensor).numpy()\n",
    "    plt.semilogy(ebno_db, ber, marker=\"o\", label=legend)\n",
    "ber_plot._bers.clear()\n",
    "ber_plot._legends.clear()\n",
    "\n",
    "\n",
    "plt.xlabel(\"Eb/N0 [dB]\")\n",
    "plt.ylabel(\"Bit Error Rate (BER)\")\n",
    "plt.title(\"Uncoded QPSK BER Curves\")\n",
    "plt.grid(True, which=\"both\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858145a-036d-4e0e-bcac-f8a4062ea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2) # we fix the seed to ensure stable convergence\n",
    "\n",
    "# init the GNN decoder\n",
    "gnn_decoder = GNN_BP(pcm=pcm,\n",
    "                     num_embed_dims=params[\"num_embed_dims\"],\n",
    "                     num_msg_dims=params[\"num_msg_dims\"],\n",
    "                     num_hidden_units=params[\"num_hidden_units\"],\n",
    "                     num_mlp_layers=params[\"num_mlp_layers\"],\n",
    "                     num_iter=params[\"num_iter\"],\n",
    "                     reduce_op=params[\"reduce_op\"],\n",
    "                     activation=params[\"activation\"],\n",
    "                     output_all_iter=True,\n",
    "                     clip_llr_to=params[\"clip_llr_to\"],\n",
    "                     use_attributes=params[\"use_attributes\"],\n",
    "                     node_attribute_dims=params[\"node_attribute_dims\"],\n",
    "                     # --- This line is now fixed ---\n",
    "                     msg_attribute_dims=params[\"msg_attribute_dims\"],\n",
    "                     use_bias=params[\"use_bias\"])\n",
    "\n",
    "# This is the 'model' you will use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc2e32-402c-40a5-b315-5e134b0cc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Forcing the GNN layer to build (passing a correctly-shaped empty tensor)...\")\n",
    "\n",
    "# 1. Define the input shape\n",
    "fake_llr_shape = (1, 160) # (batch_size=1, n_no_rm=160)\n",
    "\n",
    "# 2. Define the shape for the \"empty\" attributes tensor\n",
    "# (batch_size, num_nodes, num_attribute_dims)\n",
    "fake_attr_shape = (1, 160, 0) # num_attribute_dims is 0\n",
    "\n",
    "try:\n",
    "    # 3. Create the two fake tensors\n",
    "    fake_llr_tensor = tf.ones(fake_llr_shape, dtype=tf.float32)\n",
    "    \n",
    "    # This is the key fix: an empty tensor with the right shape and type.\n",
    "    fake_attr_tensor = tf.zeros(fake_attr_shape, dtype=tf.float32)\n",
    "    \n",
    "    # 4. Call the layer with a TUPLE of the two tensors\n",
    "    _ = gnn_decoder((fake_llr_tensor, fake_attr_tensor))\n",
    "    \n",
    "    print(\"\\nCall successful! Model should be built.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn error occurred while trying to call the model: {e}\")\n",
    "    print(\"If this fails, restart the kernel and run all cells from the top.\")\n",
    "\n",
    "# 5. Now, check the build status and print the parameters\n",
    "print(f\"\\nModel '{gnn_decoder.name}' is built: {gnn_decoder.built}\")\n",
    "print(\"Trainable Parameters:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if not gnn_decoder.trainable_weights:\n",
    "    print(\"No trainable weights found. (This is still a problem)\")\n",
    "else:\n",
    "    total_params = 0\n",
    "    for param in gnn_decoder.trainable_weights:\n",
    "        # Added ljust for better formatting\n",
    "        print(f\"Name: {param.name.ljust(60)} | Shape: {param.shape}\")\n",
    "        total_params += tf.size(param).numpy()\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total trainable parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c171955b-3f16-4a26-90ec-bbe196e0266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Sionna 1.2.1 components ---\n",
    "from sionna.phy.utils.misc import ebnodb2no\n",
    "from sionna.phy.mapping import Mapper, Demapper\n",
    "from sionna.phy.channel import RayleighBlockFading\n",
    "from sionna.phy.utils.metrics import compute_ber\n",
    "\n",
    "# --- Constants from your setup ---\n",
    "k_no_rm = pcm.shape[1] - pcm.shape[0]  # e.g., 100\n",
    "n_no_rm = pcm.shape[1]                 # e.g., 160\n",
    "coderate = k_no_rm / n_no_rm\n",
    "num_iter = params[\"num_iter\"]          # GNN iterations\n",
    "\n",
    "# --- Components for the simulation ---\n",
    "# Using BPSK (num_bits_per_symbol = 1)\n",
    "mapper = Mapper(\"pam\", num_bits_per_symbol=1)\n",
    "demapper = Demapper(\"app\", \"pam\", num_bits_per_symbol=1)\n",
    "\n",
    "# Replace BinarySource with TensorFlow-based generator\n",
    "def binary_source(batch_size, k):\n",
    "    \"\"\"Generate random binary sequences [batch_size, k].\"\"\"\n",
    "    return tf.random.uniform([batch_size, k], maxval=2, dtype=tf.int32)\n",
    "\n",
    "bce = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# --- Define the Fading Channel ---\n",
    "# âœ… Correct constructor signature for Sio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624ebce-9642-4c71-bf10-978e208f1485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "#  IMPORTS & SETUP\n",
    "# ===============================\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import os, time\n",
    "\n",
    "# --- Sionna imports ---\n",
    "from sionna.phy.utils.misc import ebnodb2no\n",
    "from sionna.phy.utils.metrics import compute_ber\n",
    "from sionna.phy.mapping import Mapper, Demapper\n",
    "\n",
    "# ===============================\n",
    "#  CONSTANTS & PARAMETERS\n",
    "# ===============================\n",
    "k_no_rm = pcm.shape[1] - pcm.shape[0]    # message bits\n",
    "n_no_rm = pcm.shape[1]                   # codeword bits\n",
    "coderate = k_no_rm / n_no_rm\n",
    "num_iter = params[\"num_iter\"]            # number of GNN iterations\n",
    "\n",
    "# ===============================\n",
    "#  MODEM, LOSS, UTILS\n",
    "# ===============================\n",
    "mapper   = Mapper(\"pam\", num_bits_per_symbol=1)\n",
    "demapper = Demapper(\"app\", \"pam\", num_bits_per_symbol=1)\n",
    "bce      = BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def binary_source(shape):\n",
    "    \"\"\"Generate random bits in {0,1}.\"\"\"\n",
    "    return tf.random.uniform(shape, maxval=2, dtype=tf.int32)\n",
    "\n",
    "def ensure_rank3(t):\n",
    "    \"\"\"Ensure tensor has shape [B, N, 1].\"\"\"\n",
    "    return t if t.shape.rank == 3 else t[..., tf.newaxis]\n",
    "\n",
    "# ===============================\n",
    "#  ANALYTIC RAYLEIGH + AWGN HELPERS\n",
    "# ===============================\n",
    "def sample_rayleigh_block_fading(B, N, complex_channel=True, dtype=tf.float32):\n",
    "    \"\"\"Return Rayleigh fading h with shape [B, N, 1].\"\"\"\n",
    "    if complex_channel:\n",
    "        h_r = tf.random.normal([B, N, 1], mean=0.0, stddev=1/np.sqrt(2), dtype=dtype)\n",
    "        h_i = tf.random.normal([B, N, 1], mean=0.0, stddev=1/np.sqrt(2), dtype=dtype)\n",
    "        return tf.complex(h_r, h_i)\n",
    "    else:\n",
    "        return tf.random.normal([B, N, 1], mean=0.0, stddev=1.0, dtype=dtype)\n",
    "\n",
    "def add_awgn(y, no_sym, complex_noise=True):\n",
    "    \"\"\"Add AWGN with noise variance N0 per symbol.\"\"\"\n",
    "    if complex_noise:\n",
    "        std = tf.sqrt(no_sym / 2.0)\n",
    "        n_r = tf.random.normal(tf.shape(y), mean=0.0, stddev=1.0, dtype=y.dtype.real_dtype)\n",
    "        n_i = tf.random.normal(tf.shape(y), mean=0.0, stddev=1.0, dtype=y.dtype.real_dtype)\n",
    "        w   = tf.complex(std * n_r, std * n_i)\n",
    "    else:\n",
    "        std = tf.sqrt(no_sym)\n",
    "        w   = std * tf.random.normal(tf.shape(y), mean=0.0, stddev=1.0, dtype=y.dtype)\n",
    "    return y + w\n",
    "\n",
    "def llr_perfect_csi(y, h, no_sym):\n",
    "    \"\"\"\n",
    "    Compute per-symbol LLRs with perfect CSI.\n",
    "    For BPSK: LLR = (2 / N0) * Re{ conj(h) * y }.\n",
    "    y: [B,N,1], complex or real\n",
    "    h: [B,N,1], complex or real\n",
    "    no_sym: [B,1,1] float (N0 per symbol)\n",
    "    Returns: [B,N,1] float32\n",
    "    \"\"\"\n",
    "    y_c = tf.cast(y, tf.complex64)\n",
    "    h_c = tf.cast(h, tf.complex64)\n",
    "    corr = tf.math.real(tf.math.conj(h_c) * y_c)  # float32\n",
    "    n0 = tf.cast(no_sym, tf.float32)\n",
    "    llr = (2.0 / n0) * corr\n",
    "    return tf.cast(llr, tf.float32)\n",
    "\n",
    "# ===============================\n",
    "#  OPTIMIZER & CHECKPOINTS\n",
    "# ===============================\n",
    "optimizer = Adam(learning_rate=params[\"learning_rate\"][0])\n",
    "checkpoint_dir = os.path.join(params[\"save_dir\"], params[\"run_name\"], \"checkpoints\")\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(model=gnn_decoder)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_dir, max_to_keep=5)\n",
    "\n",
    "# ===============================\n",
    "#  TRAIN STEP (fixed)\n",
    "# ===============================\n",
    "@tf.function(jit_compile=True)\n",
    "def train_step(batch_size, ebno_db_range):\n",
    "    \"\"\"One training iteration over Rayleigh block fading channel.\"\"\"\n",
    "    # 1) Random Eb/N0 in training range\n",
    "    ebno_db = tf.random.uniform([batch_size],\n",
    "                                minval=ebno_db_range[0],\n",
    "                                maxval=ebno_db_range[1],\n",
    "                                dtype=tf.float32)\n",
    "\n",
    "    # 2) Generate bits, encode, map\n",
    "    b = binary_source([batch_size, k_no_rm])  # [B,k]\n",
    "    c = encoder_no_rm(b)                      # [B,n]\n",
    "    x = mapper(c)\n",
    "    x = ensure_rank3(x)                       # [B,n,1]\n",
    "\n",
    "    # 3) Compute N0\n",
    "    no = ebnodb2no(ebno_db, num_bits_per_symbol=1, coderate=coderate)  # [B]\n",
    "    no_sym = tf.reshape(no, [-1, 1, 1])                                # [B,1,1]\n",
    "\n",
    "    # 4) Rayleigh + AWGN\n",
    "    h = sample_rayleigh_block_fading(batch_size, n_no_rm, complex_channel=True, dtype=tf.float32)\n",
    "    y = h * tf.cast(x, tf.complex64)\n",
    "    y = add_awgn(y, no_sym, complex_noise=True)\n",
    "\n",
    "    # 5) LLR computation\n",
    "    y = tf.cast(y, tf.complex64)\n",
    "    h = tf.cast(h, tf.complex64)\n",
    "    llrs_in = llr_perfect_csi(y, h, no_sym)  # [B,n,1]\n",
    "    h_context = tf.square(tf.abs(h))\n",
    "\n",
    "    # 6) GNN forward + loss\n",
    "    with tf.GradientTape() as tape:\n",
    "        # --- FIX 1: Handle the list output from the GNN ---\n",
    "        # gnn_decoder returns a LIST of 10 tensors, each with shape [B, N]\n",
    "        c_hat_list = gnn_decoder((llrs_in, h_context))\n",
    "\n",
    "        # Stack the list to create a single [B, T, N] tensor\n",
    "        # T (num_iter) is 10\n",
    "        c_hat_iter = tf.stack(c_hat_list, axis=1) \n",
    "        # ------------------------------------------------\n",
    "\n",
    "        # ðŸ”¹ Repeat labels for loss calculation\n",
    "        c_rep = tf.expand_dims(tf.cast(c, tf.float32), axis=1)  # [B,1,N]\n",
    "        c_rep = tf.tile(c_rep, [1, num_iter, 1])                # [B,T,N]\n",
    "\n",
    "        loss = bce(c_rep, c_hat_iter)\n",
    "\n",
    "    # 7) Backprop\n",
    "    grads = tape.gradient(loss, gnn_decoder.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, gnn_decoder.trainable_weights))\n",
    "    return loss\n",
    "\n",
    "# ===============================\n",
    "#  EVAL STEP (fixed)\n",
    "# ===============================\n",
    "@tf.function(jit_compile=True)\n",
    "def eval_step(batch_size, ebno_db):\n",
    "    \"\"\"Evaluate BER for fixed Eb/N0 under Rayleigh block fading.\"\"\"\n",
    "    b = binary_source([batch_size, k_no_rm])\n",
    "    c = encoder_no_rm(b)\n",
    "    x = mapper(c)\n",
    "    x = ensure_rank3(x)\n",
    "\n",
    "    no = ebnodb2no(ebno_db, num_bits_per_symbol=1, coderate=coderate)\n",
    "    no_sym = tf.reshape(no, [1, 1, 1])\n",
    "\n",
    "    h = sample_rayleigh_block_fading(batch_size, n_no_rm, complex_channel=True, dtype=tf.float32)\n",
    "    y = h * tf.cast(x, tf.complex64)\n",
    "    y = add_awgn(y, no_sym, complex_noise=True)\n",
    "\n",
    "    y = tf.cast(y, tf.complex64)\n",
    "    h = tf.cast(h, tf.complex64)\n",
    "    llrs_in = llr_perfect_csi(y, h, no_sym)\n",
    "\n",
    "    h_context = tf.square(tf.abs(h))\n",
    "    \n",
    "    # --- FIX 2: Handle the list output from the GNN ---\n",
    "    # gnn_decoder returns a LIST of 10 tensors, each with shape [B, N]\n",
    "    c_hat_list = gnn_decoder((llrs_in, h_context))\n",
    "\n",
    "    # For evaluation, we only need the output from the *final* iteration\n",
    "    c_hat_llrs = c_hat_list[-1]  # Shape is [B, N]\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    c_hat = tf.cast(c_hat_llrs < 0.0, tf.int32)\n",
    "    ber = compute_ber(tf.cast(c, tf.int32), c_hat)\n",
    "    return ber\n",
    "\n",
    "# ===============================\n",
    "#  TRAINING LOOP\n",
    "# ===============================\n",
    "print(\"Starting training...\")\n",
    "print(f\"Code: {params['code']} (n={n_no_rm}, k={k_no_rm})\")\n",
    "print(f\"GNN Iterations: {num_iter}\")\n",
    "print(\"Training on Rayleigh block fading (analytic)\\n\")\n",
    "\n",
    "train_batch_size = params[\"batch_size\"][0]\n",
    "eval_batch_size  = params[\"batch_size_eval\"]\n",
    "ebno_db_train    = params[\"ebno_db_train\"]    # e.g., [2.0, 8.0]\n",
    "ebno_db_eval     = params[\"ebno_db_eval\"]     # e.g., 2.0\n",
    "total_train_iter = params[\"train_iter\"][0]\n",
    "eval_steps       = params[\"eval_train_steps\"]\n",
    "save_steps       = params[\"save_weights_iter\"]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1, total_train_iter + 1):\n",
    "    loss = train_step(train_batch_size, ebno_db_train)\n",
    "    loss_val = float(loss.numpy())\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        print(f\"Iter: {i:6d} | Loss: {loss_val:.4f} | Time: {elapsed:.1f}s\")\n",
    "        start_time = time.time()\n",
    "\n",
    "    if i % eval_steps == 0:\n",
    "        print(f\"\\n--- Evaluating model at Eb/No = {ebno_db_eval} dB ---\")\n",
    "        num_eval_batches = 100\n",
    "        ber_vals = []\n",
    "        for _ in range(num_eval_batches):\n",
    "            ber = eval_step(eval_batch_size, ebno_db_eval)\n",
    "            ber_vals.append(float(ber.numpy()))\n",
    "        ber_avg = sum(ber_vals) / len(ber_vals)\n",
    "        print(f\"Iter: {i:6d} | EVAL BER: {ber_avg:.6e}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "    if i % save_steps == 0:\n",
    "        save_path = ckpt_manager.save(checkpoint_number=i)\n",
    "        print(f\"Iter: {i:6d} | Saved checkpoint to {save_path}\")\n",
    "\n",
    "print(\"Training finished successfully âœ…\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Sionna)",
   "language": "python",
   "name": "sionna_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
